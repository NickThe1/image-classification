{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-10-24T20:21:01.410317Z","iopub.execute_input":"2022-10-24T20:21:01.410732Z","iopub.status.idle":"2022-10-24T20:21:01.418615Z","shell.execute_reply.started":"2022-10-24T20:21:01.410699Z","shell.execute_reply":"2022-10-24T20:21:01.417387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modern Convolutional Neural Networks\n\n\n### Description\n\nIn this homework, you need to write a convolutional neural network for image classification.\n\nYou have been provided with a modified dataset of The Street View House Numbers ([SVHN](http://ufldl.stanford.edu/housenumbers/)). It contains 50 thousand (train) + 25 thousand (test) 32x32 RGB images with numbers cut from real photos of house numbers.\n\nTask: use convolutional neural networks to achieve maximum classification accuracy.\n\nIn this homework task, there are no restrictions on the architecture of the model, but you **need to implement it in PyTorch by yourself** and train it from scratch only on this dataset, without external data.\n\n### Data\n\nThis notebook already has the code for PyTorch responsible for loading the data. The following is a brief description of the data storage format.\n\nEach of the files is a `pickle` serialized with protocol version 4 (which became the default version in Python 3.8 and later) a python dictionary.\n\nList of files:\n\n- `meta` - dataset metadata (for example, class names)\n- `data_train` - training data, 50K objects\n- `data_test` - data for the test, 25K objects, without the correct classes\n\nData dictionaries have the following fields:\n\n- `section` — name of the data part (train/test)\n- `labels` - ground-truth classes, list of `N` numbers from 0 to 9\n- `images` - numpy array of size `(N, 32, 32, 3)` with images\n\n### Grade\n\nThe quality of the solution will be evaluated by the metric accuracy. Accuracy is the number of correctly classified pictures to the total number of pictures in the test set. The public leaderboard is calculated using 30% of the test data, so try not to retrain for it.\n\n```\naccuracy = (correct classified) / (total number of examples)\n```\n\nAs a solution, you should send a file of the format:\n\n```\nID,Category\n0, 3\n1, 2\n2, 9\n3, 1\n...\n```\n\nwhere:\n\n- `Id` — number of the object in the test dataset\n- `Category` — predicted object class\n\nThis notebook already has the code that prepares the solution file.\n\n### Experiments\n\nSince there are so many different hyperparameters in training a neural network model, many different experiments will need to be done in this task. And it will be very useful, both for you and for us, who check, the presence of a text description of all, or at least the most interesting/important in choosing the final model, experiments with the results in the final notebook. The presence and detail of the description of the experiments will be included in the final grade for the homework. The deadline on Kaggle is specially set a little earlier so that you have time to calmly finish the report on the experiments.","metadata":{}},{"cell_type":"markdown","source":"## Baseline solution","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import trange\nfrom IPython.display import clear_output","metadata":{"execution":{"iopub.status.busy":"2022-11-04T15:52:38.812061Z","iopub.execute_input":"2022-11-04T15:52:38.813034Z","iopub.status.idle":"2022-11-04T15:52:38.843991Z","shell.execute_reply.started":"2022-11-04T15:52:38.812906Z","shell.execute_reply":"2022-11-04T15:52:38.842740Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pickle\nfrom typing import Any, Callable, Optional, Tuple\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2022-11-04T15:52:49.778224Z","iopub.execute_input":"2022-11-04T15:52:49.778700Z","iopub.status.idle":"2022-11-04T15:52:49.785852Z","shell.execute_reply.started":"2022-11-04T15:52:49.778664Z","shell.execute_reply":"2022-11-04T15:52:49.784085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision.transforms import ToTensor, Compose\nfrom torchvision.datasets.vision import VisionDataset","metadata":{"execution":{"iopub.status.busy":"2022-11-04T15:53:15.820225Z","iopub.execute_input":"2022-11-04T15:53:15.820654Z","iopub.status.idle":"2022-11-04T15:53:18.111698Z","shell.execute_reply.started":"2022-11-04T15:53:15.820621Z","shell.execute_reply":"2022-11-04T15:53:18.110114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The data is in the [Data](https://www.kaggle.com/c/sirius-spbsu-2022-entry-competition/data) section of the kaggle competition. <br>\nYou need to download the archive with the data and unzip it. <br>\nIn the variable below, specify the path to the dataset. <br>","metadata":{}},{"cell_type":"code","source":"dataset_root = \"/kaggle/input/kbtu-ml-2022-image-classification\"","metadata":{"execution":{"iopub.status.busy":"2022-11-04T15:53:59.604312Z","iopub.execute_input":"2022-11-04T15:53:59.605860Z","iopub.status.idle":"2022-11-04T15:53:59.611699Z","shell.execute_reply.started":"2022-11-04T15:53:59.605815Z","shell.execute_reply":"2022-11-04T15:53:59.610215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Code for loading the modified SVHN dataset. Initialization Arguments:\n\n- `root` — string, path to directory with dataset files\n- `is_train` — flag, load part for training or test\n- `transform` — image transformations\n- `target_transform` — image class transformations","metadata":{}},{"cell_type":"code","source":"class SVHN(VisionDataset):\n\n    def __init__(self,\n                 root: str,\n                 is_train: bool = True,\n                 transform: Optional[Callable] = None,\n                 target_transform: Optional[Callable] = None,\n                 ) -> None:\n\n        super().__init__(root, transform=transform, target_transform=target_transform)\n        self.is_train = is_train\n\n        meta_path = os.path.join(self.root, 'meta')\n        with open(meta_path, \"rb\") as f:\n            content = pickle.load(f)\n            self.classes = content['label_names']\n            self.class_to_idx = {_class: i for i, _class in enumerate(self.classes)}\n\n        data_path = os.path.join(self.root, 'data_train' if is_train else 'data_test')\n        with open(data_path, \"rb\") as f:\n            content = pickle.load(f)\n            self.data = content['images']\n            self.targets = content.get('labels')\n\n    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n        img = Image.fromarray(self.data[index].astype(np.uint8))\n        target = self.targets[index] if self.is_train else len(self.classes)\n        if self.transform is not None:\n            img = self.transform(img)\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n        return img, target\n\n    def __len__(self) -> int:\n        return len(self.data)\n        \n    def extra_repr(self) -> str:\n        split = \"Train\" if self.train is True else \"Test\"\n        return f\"Split: {split}\"","metadata":{"execution":{"iopub.status.busy":"2022-11-04T15:56:09.515754Z","iopub.execute_input":"2022-11-04T15:56:09.516261Z","iopub.status.idle":"2022-11-04T15:56:09.529901Z","shell.execute_reply.started":"2022-11-04T15:56:09.516227Z","shell.execute_reply":"2022-11-04T15:56:09.528922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataset download","metadata":{}},{"cell_type":"code","source":"data = SVHN(\n    root=dataset_root,\n    is_train=True,\n    transform=ToTensor(),\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T15:56:17.423974Z","iopub.execute_input":"2022-11-04T15:56:17.424385Z","iopub.status.idle":"2022-11-04T15:56:23.062972Z","shell.execute_reply.started":"2022-11-04T15:56:17.424354Z","shell.execute_reply":"2022-11-04T15:56:23.061188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We randomly split the dataset into training and validation. <br>\nIn the first part, we will train the classification model. <br>\nIn the second part, we will evaluate the quality during the experiments. <br>","metadata":{}},{"cell_type":"code","source":"train_data, val_data = torch.utils.data.random_split(\n    data, \n    [40000, 10000], \n    generator=torch.Generator().manual_seed(137),\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data loaders initialization.","metadata":{}},{"cell_type":"code","source":"batch_size = 64\ntrain_dataloader = DataLoader(train_data, batch_size=batch_size)\nval_dataloader = DataLoader(val_data, batch_size=batch_size)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see what size batches the data loader produces.","metadata":{}},{"cell_type":"code","source":"for X, y in train_dataloader:\n    print(\"Shape of X [N, C, H, W]: \", X.shape)\n    print(\"Shape of y: \", y.shape, y.dtype)\n    break","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Classification model","metadata":{}},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Using {} device\".format(device))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We set the architecture of the classification model. <br>\nThere is a lot of room for different experiments. <br>","metadata":{}},{"cell_type":"code","source":"model = nn.Sequential(\n    nn.Flatten(),\n    nn.Linear(3*32*32, 10),\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We send the model to the selected device.","metadata":{}},{"cell_type":"code","source":"model = model.to(device)\nprint(model)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"markdown","source":"We set the loss function (optimization goal) and the optimizer.","metadata":{}},{"cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Code for visualizing the learning process.\n\nEvery `interval` optimization steps and at the end of epochs, we write the values of the loss function and metrics to the log. <br>\nThen, by calling the `show_progress` function, we update the training schedule. <br>","metadata":{}},{"cell_type":"code","source":"# Training logs\ninterval = 100\ntrain_ts, train_loss = [], []\nval_ts, val_loss, val_acc = [], [], []","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_progress(t):\n    clear_output(wait=True)\n    fig, (ax1, ax2) = plt.subplots(1, 2, constrained_layout=True, figsize=(20, 5))\n    fig.suptitle(f'Epoch {t:3.3f}', fontsize=16)\n    ax1.set_title('loss')\n    ax1.set_xlabel('time (epochs)')\n    ax1.set_ylabel('loss')\n    ax1.plot(train_ts, train_loss, c='darkblue', lw=3)\n    ax1.plot(val_ts, val_loss, c='green', marker='o', lw=5)\n    ax2.set_title('accuracy')\n    ax2.set_xlabel('time (epochs)')\n    ax2.plot(val_ts, val_acc, c='green', marker='o', lw=5)\n    plt.show() ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(epoch, dataloader, model, loss_fn, optimizer):\n    model.train()\n    num_batches = len(dataloader)\n    for batch, (X, y) in enumerate(dataloader):\n        # Send data to training device\n        X, y = X.to(device), y.to(device)\n        # Compute prediction error\n        pred = model(X)\n        loss = loss_fn(pred, y)\n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        # Progress output\n        if batch % interval == 0:\n            t = epoch + (batch + 1)/num_batches\n            train_ts.append(t)\n            train_loss.append(loss.item())\n            show_progress(t)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test(epoch, dataloader, model, loss_fn):\n    model.eval()\n    num_batches = len(dataloader)\n    size = len(dataloader.dataset)\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    test_loss /= num_batches\n    correct /= size\n    val_ts.append(epoch+1)\n    val_loss.append(test_loss)\n    val_acc.append(correct)\n    show_progress(epoch+1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training loop.","metadata":{}},{"cell_type":"code","source":"epochs = 50\nfor t in trange(epochs):\n    train(t, train_dataloader, model, loss_fn, optimizer)\n    test(t, val_dataloader, model, loss_fn)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submit solution","metadata":{}},{"cell_type":"markdown","source":"Download the test part of the dataset.","metadata":{}},{"cell_type":"code","source":"test_data = SVHN(\n    root=dataset_root,\n    is_train=False,\n    transform=ToTensor(),\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataloader = DataLoader(\n    test_data, \n    batch_size=batch_size,\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We make predictions by the final model.","metadata":{}},{"cell_type":"code","source":"predictions = []\n\nmodel.eval()\nwith torch.no_grad():\n    for X, _ in test_dataloader:\n        X = X.to(device)\n        pred = model(X).argmax(1).cpu().numpy()\n        predictions.extend(list(pred))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def write_solution(filename, labels):\n    with open(filename, 'w') as solution:\n        print('Id,Category', file=solution)\n        for i, label in enumerate(labels):\n            print(f'{i},{label}', file=solution)\n            \nwrite_solution('solution.csv', predictions)","metadata":{},"execution_count":null,"outputs":[]}]}